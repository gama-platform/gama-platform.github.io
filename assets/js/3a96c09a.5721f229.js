"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[88921],{36188:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>a,default:()=>c,frontMatter:()=>s,metadata:()=>l,toc:()=>d});var i=n(74848),o=n(28453);const s={title:"2. BDI Agents"},a=void 0,l={id:"BDIAgents_step2",title:"2. BDI Agents",description:"This second step consists in defining the gold miner agents using the GAMA BDI architecture.",source:"@site/versioned_docs/version-1.9.2/BDIAgents_step2.md",sourceDirName:".",slug:"/BDIAgents_step2",permalink:"/wiki/BDIAgents_step2",draft:!1,unlisted:!1,editUrl:"https://github.com/gama-platform/gama/wiki/BDIAgents_step2/_edit",tags:[],version:"1.9.2",frontMatter:{title:"2. BDI Agents"},sidebar:"tuto",previous:{title:"1. Skeleton model",permalink:"/wiki/BDIAgents_step1"},next:{title:"3. Social relation",permalink:"/wiki/BDIAgents_step3"}},r={},d=[{value:"Formulation",id:"formulation",level:2},{value:"BDI agents",id:"bdi-agents",level:2},{value:"Model Definition",id:"model-definition",level:2},{value:"predicates",id:"predicates",level:3},{value:"skeleton of the miner species",id:"skeleton-of-the-miner-species",level:3},{value:"perception",id:"perception",level:3},{value:"rules",id:"rules",level:3},{value:"plans",id:"plans",level:3},{value:"Gobal section",id:"gobal-section",level:2},{value:"Map display",id:"map-display",level:2},{value:"Complete Model",id:"complete-model",level:2}];function h(e){const t={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"This second step consists in defining the gold miner agents using the GAMA BDI architecture."}),"\n",(0,i.jsx)(t.h2,{id:"formulation",children:"Formulation"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Definition of global predicates"}),"\n",(0,i.jsx)(t.li,{children:"Definition of the gold miner species"}),"\n",(0,i.jsx)(t.li,{children:"Definition of the gold miner perceptions"}),"\n",(0,i.jsx)(t.li,{children:"Definition of the gold miner rules"}),"\n",(0,i.jsx)(t.li,{children:"Definition of the gold miner plans"}),"\n",(0,i.jsx)(t.li,{children:"Creation and display of the gold miners"}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"bdi-agents",children:"BDI agents"}),"\n",(0,i.jsxs)(t.p,{children:["A classic paradigm to formalize the internal architecture of cognitive agents in Agent-Oriented Software Engineering is the BDI (Belief-Desire-Intention) paradigm. This paradigm, based on the philosophy of action ",(0,i.jsx)(t.a,{href:"https://philpapers.org/rec/braipa",children:"(Bratman, 1987)"}),", allows to design expressive and realistic agents."]}),"\n",(0,i.jsx)(t.p,{children:"The concepts of Belief-Desire-Intention can be summarized as follow for the Gold Miner: the Miner agent has a general desire to find gold. As it is the only thing it wants at the beginning, it is its initial intention (what it is currently doing). To find gold, it wanders around (its plan is to wander). When it perceives some gold nuggets, it stores this information (it has a new belief about the existence and location of this gold nugget), and it adopts a new desire (it wants to extract the gold). When it perceives a gold nugget, the intention to find gold is put on hold and a new intention is selected (to extract gold). To achieve this intention, the plan has two steps, i.e. two new (sub)intentions: to choose a gold nugget to extract (among its known gold nuggets) and to go and take it. And so on."}),"\n",(0,i.jsx)(t.p,{children:"In GAMA, we propose a control architecture for agents based on this paradigm. This control architecture provides the agents with 3 databases linked to the agent cognition (that are 3 additional variables):"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.code,{children:"belief_base"})})," (what it knows): the internal knowledge the agent has about the world or about its internal state, updated during the simulation. A belief can concern any type of information (a quantity, a location, a boolean value, etc)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.code,{children:"desire_base"})})," (what it wants): objectives that the agent would like to accomplish, also updated during the simulation. Desires can have hierarchical links (sub/super desires) when a desire is created as an intermediary objective."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.code,{children:"intention_base"})})," (what it is doing): what the agent has chosen to do. The current intention will determine the selected plan. Intentions can be put on hold (for example when they require a sub-intention to be achieved)."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"In addition, the BDI architecture provides agents with three types of behavior structures:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Perception"}),": a perception is a function executed at each iteration to update the agent's Belief base, to know the changes in its environment (the world, the other agents and itself). The agent can perceive other agents up to a fixed distance or inside a specific geometry."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Rule"}),": a rule is a function executed at each iteration to infer new desires or beliefs from the agent's current beliefs and desires, i.e. a new desire or belief can emerge from the existing ones."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Plan"}),": the agent has a set of plans, which are behaviors defined to accomplish specific intentions. Plans can be instantaneous and/or persistent and may have a priority value (that can be dynamic), used to select a plan when several possible plans are available to accomplish the same intention."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["To be more precise on the behavior of BDI agents (what the agent is going to do when activated), this one is composed of 10 steps (see ",(0,i.jsx)(t.a,{href:"https://hal.archives-ouvertes.fr/hal-01216165/document",children:"(Caillou et al., 2017)"})," and ",(0,i.jsx)(t.a,{href:"https://hal.archives-ouvertes.fr/hal-01391002/document",children:"(Taillandier et al., 2016)"})," for more details):"]}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Perceive"}),": Perceptions are executed."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Rule"}),": Rules are executed."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Is one of my intentions achieved?"}),": If one of my intentions is achieved, sets the current plan to nil and removes the intention from the intention base. If the achieved intention's super-intention is on hold, it is reactivated (its sub-intention just got completed)."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Do I keep the current intention?"}),": To take into account the environment instability, an intention-persistence coefficient is applied: with this probability, the current intention is removed from the intention stack."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Do I have a current plan?"}),": If I have a current plan, just execute it. Similarly to intentions, a plan-persistence coefficient is defined: with this probability, the current plan is just dropped."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Choose a desire as new current intention"}),": If the current intention is on hold (or the intention base is empty), choose a desire as new current intention. The new selected intention is the desire with higher priority."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Choose a plan as a new current plan"}),": The new current plan is selected among the plans compatible with the current intention (and if their activation condition is checked) and with the highest priority."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Execute the plan"}),": The current plan is executed."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Is my plan finished?"}),": To allow persistent plans, a plan may have a termination condition. If it is not reached, the same plan will be kept for the next iteration."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.em,{children:"Was my plan instantaneous?"}),': Most agent-based simulation frameworks (GAMA included) are synchronous frameworks using steps. One consequence is that it may be useful to apply several plans during one single step. For example, if a step represents a day or a year, it would be unrealistic for an agent to spend one step to apply a plan like "choose a destination". This kind of plans (mostly reasoning plans) can be defined as instantaneous: in this case a new thinking loop is applied during the same agent step.']}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"The architecture introduces two new main types of variables related to cognition:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.code,{children:"predicate"})}),": a predicate unifies the representation of the information about the world. It can represent a situation, an event or an action."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:(0,i.jsx)(t.code,{children:"mental_state"})}),": it represents the element (belief, desire, intention) manipulated by the agent and the architecture to take a decision. A mental state is composed of a modality, a predicate or another mental state, a real value and a lifetime. The modality indicates the type of the mental state (e.g. a belief or a desire), the predicate indicates the fact about which is this mental state (a mental state can also be about another mental state like a belief about a belief, etc), the value has a different interpretation depending on the modality and finally, the lifetime indicates the duration of the mental state (it can be infinite)."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"model-definition",children:"Model Definition"}),"\n",(0,i.jsx)(t.h3,{id:"predicates",children:"predicates"}),"\n",(0,i.jsx)(t.p,{children:"As a first step of the integration of the BDI agents in our model, we define a set of global predicates that will represent all the information that will be manipulated by the miner agents:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"mine_location"}),": represents the information about the location of a gold mine."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"choose_gold_mine"}),": represents the information that the miner wants to choose a gold mine."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"has_gold"}),": represents the information that the miner has a gold nugget."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"find_gold"}),": represents the information that the miner wants to find gold."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"sell_gold"}),": represents the information that the miner wants to sell gold."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["We define as well two global string (",(0,i.jsx)(t.em,{children:"mine_at_location"})," and ",(0,i.jsx)(t.em,{children:"empty_mine_location"}),") for simplification purpose and to avoid misspellings."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'global {\n    ...\n    string mine_at_location <- "mine_at_location";\n    string empty_mine_location <- "empty_mine_location";\n\t\n    predicate mine_location <- new_predicate(mine_at_location) ;\n    predicate choose_gold_mine <- new_predicate("choose a gold mine");\n    predicate has_gold <- new_predicate("extract gold");\n    predicate find_gold <- new_predicate("find gold") ;\n    predicate sell_gold <- new_predicate("sell gold") ;\n    ...\n}\n'})}),"\n",(0,i.jsx)(t.h3,{id:"skeleton-of-the-miner-species",children:"skeleton of the miner species"}),"\n",(0,i.jsxs)(t.p,{children:["We then define a miner species with the ",(0,i.jsx)(t.code,{children:"moving"})," skill and the ",(0,i.jsx)(t.code,{children:"simple_bdi"})," control architecture. The miner agents have 5 variables:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"view_dist"}),": distance of perception of the miner agent"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"speed"}),": speed of the agent"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"my_color"}),": the color of the agent (random color)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"target"}),": where the agent wants to go"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"gold_sold"}),": the number of gold nuggets sold by the agent"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["We define the init block of the species such as to add at the creation of the agent the desire to find gold nuggets (",(0,i.jsx)(t.code,{children:"find_gold"})," predicate). we use for that the ",(0,i.jsx)(t.code,{children:"add_desire"})," action provides with the BDI architecture."]}),"\n",(0,i.jsxs)(t.p,{children:["At last, we define an aspect in which we draw the agent with its ",(0,i.jsx)(t.code,{children:"my_color"})," color and with a depth that depends on the number of gold nuggets collected. We then add a circle around the miner of radius ",(0,i.jsx)(t.code,{children:"view_dist"})," to visualize the distance of perception of each agent, we set the ",(0,i.jsx)(t.code,{children:"wireframe"})," facet to true in order to draw only its border."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"species miner skills: [moving] control:simple_bdi {\n    float view_dist <- 1000.0;\n    float speed <- 2#km/#h;\n    rgb my_color <- rnd_color(255);\n    point target;\n    int gold_sold;\n\t\n    init {\n\tdo add_desire(find_gold);\n    }\n    aspect default {\n        draw circle(200) color: my_color border: #black depth: gold_sold;\n        draw circle(view_dist) color: my_color border: #black depth: gold_sold wireframe: true;\n    }\n}\n"})}),"\n",(0,i.jsx)(t.h3,{id:"perception",children:"perception"}),"\n",(0,i.jsxs)(t.p,{children:["We add a ",(0,i.jsx)(t.em,{children:"perceive"})," statement for the miner agents. This perceive will allow the agent to detect the gold mines that are not empty (i.e. the quantity of gold is higher than 0) at a distance lower or equal to ",(0,i.jsx)(t.code,{children:"view_dist"}),". The use of the ",(0,i.jsx)(t.code,{children:"focus"})," statement allows adding for each detected gold mine a belief corresponding to the location of this gold mine. The name of the belief will be ",(0,i.jsx)(t.code,{children:"mine_at_location"})," and the location value of the gold_mine will be stored in the ",(0,i.jsx)(t.code,{children:"values"})," (a map) variable of the belief at the key ",(0,i.jsx)(t.code,{children:"location_value"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["In addition, we ask the miner agent to remove the intention to find gold, allowing the agent to choose a new intention. The boolean value of the ",(0,i.jsx)(t.code,{children:"remove_intention"})," action is used to specify if the agent should or not remove the given intention from the desire base as well. In our case, we choose to keep the desire to find golds."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"species miner skills: [moving] control: simple_bdi {\n    ...\t\n    perceive target: gold_mine where (each.quantity > 0) in: view_dist {\n\tfocus id: mine_at_location var:location;\n\task myself {\n\t    do remove_intention(find_gold, false);\n\t}\n    }\n}\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Note that the perceive statement works as the ",(0,i.jsx)(t.code,{children:"ask"})," statement: the instructions written in the statement are executed in the context of the perceive agents. It is for that that we have to use the ",(0,i.jsx)(t.code,{children:"myself"})," keyword to ask the miner agent to execute the ",(0,i.jsx)(t.code,{children:"remove_intention"})," action."]}),"\n",(0,i.jsx)(t.h3,{id:"rules",children:"rules"}),"\n",(0,i.jsx)(t.p,{children:"We define two rules for the miner agents:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"if the agent believes that there is somewhere at least one gold mine with gold nuggets, the agent gets the new desire to has a gold nugget with a strength of 2."}),"\n",(0,i.jsx)(t.li,{children:"if the agent believes that it has a gold nugget, the agent gets the new desire to sell the gold nugget with a strength of 3."}),"\n"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"species miner skills: [moving] control:simple_bdi {\n    ...\n    rule belief: mine_location new_desire: has_gold strength: 2.0;\n    rule belief: has_gold new_desire: sell_gold strength: 3.0;\n}\n"})}),"\n",(0,i.jsxs)(t.p,{children:["The strength of a desire will be used when selecting a desire as a new intention: the agent will choose as new intention the one with the highest strength. In our model, if the agent has the desires to find gold, to has gold and to sell gold, it will choose as intention to sell gold as it is the one with the highest strength. It is possible to replace this deterministic choice by a probabilistic one by setting the ",(0,i.jsx)(t.code,{children:"probabilistic_choice"})," built-in variable of the BDI agent to true (false by default)."]}),"\n",(0,i.jsx)(t.h3,{id:"plans",children:"plans"}),"\n",(0,i.jsx)(t.p,{children:"The last (and most important) part of the definition of BDI agents consists in defining the plans that the agents can carry out to achieve its intention."}),"\n",(0,i.jsxs)(t.p,{children:["The first plan called ",(0,i.jsx)(t.code,{children:"lets_wander"})," is defined to achieve the ",(0,i.jsx)(t.code,{children:"find_gold"})," intention. This plan will just consist of executing the ",(0,i.jsx)(t.code,{children:"wander"})," action of the ",(0,i.jsx)(t.code,{children:"moving"})," skill (random move)."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"species miner skills: [moving] control: simple_bdi {\n    ...\n    plan lets_wander intention: find_gold {\n\tdo wander;\n    }\n    ...\n}\n"})}),"\n",(0,i.jsxs)(t.p,{children:["The second plan called ",(0,i.jsx)(t.code,{children:"get_gold"})," is defined to achieve the ",(0,i.jsx)(t.code,{children:"has_gold"})," intention. If the agent has no target (it does not know where to go), it adds a new sub-intention to choose a gold mine and puts the current intention on hold (the agent will wait to select a gold mine to go before executing again this plan). The ",(0,i.jsx)(t.code,{children:"add_subintention"})," operator is used to this purpose and has 3 arguments: the sub-intention (",(0,i.jsx)(t.code,{children:"choose_gold_mine"}),"), the super intention (",(0,i.jsx)(t.code,{children:"has_gold"}),") and a boolean that defines if the sub-intention should or not be added as well as a desire. The super intention (this is in fact the current intention) can be accessed with ",(0,i.jsx)(t.code,{children:"get_current_intention()"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["If the agent has already a target, it moves toward this target using the ",(0,i.jsx)(t.code,{children:"goto"})," action of the ",(0,i.jsx)(t.code,{children:"moving"})," skill. If the agent reaches its target (a gold mine) (target = location), the agent tries to extract gold nuggets from it. If the corresponding gold mine (that one located at the target location) is not empty, the agent extracts a gold nugget from it: the agent adds the belief that it has a gold nugget, then the quantity of golds in the gold mine is reduced. Otherwise, if the gold mine is empty, the agent adds the belief that this gold mine is empty and the target is set to nil."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'species miner skills: [moving] control:simple_bdi {\n    ...\n    plan get_gold intention:has_gold {\n\tif (target = nil) {\n\t    do add_subintention(get_current_intention(),choose_gold_mine, true);\n\t    do current_intention_on_hold();\n\t} else {\n\t    do goto target: target ;\n\t    if (target = location)  {\n\t\tgold_mine current_mine<- gold_mine first_with (target = each.location);\n\t\tif current_mine.quantity > 0 {\n\t\t    do add_belief(has_gold);\n\t\t    ask current_mine {quantity <- quantity - 1;}\t\n\t\t} else {\n\t\t    do add_belief(new_predicate(empty_mine_location, ["location_value"::target]));\n\t\t}\n\t\ttarget <- nil;\n\t    }\n\t}\t\n    }\n    ...\n}\n'})}),"\n",(0,i.jsxs)(t.p,{children:["The third plan called ",(0,i.jsx)(t.code,{children:"choose_closest_gold_mine"})," is defined to achieve the ",(0,i.jsx)(t.code,{children:"choose_gold_mine"})," intention that is instantaneous. First, the agent defines the list of all the gold mines it knows (",(0,i.jsx)(t.code,{children:"mine_at_location"})," beliefs), then removes the gold mines that it knows that they are empty (",(0,i.jsx)(t.code,{children:"empty_mine_location"})," beliefs). If the list of the possible mines is empty, the agent removes the desire and the intention to ",(0,i.jsx)(t.code,{children:"extract_gold"}),". We use for that the ",(0,i.jsx)(t.code,{children:"remove_intention"})," action, that removes an intention from the intention base; the second argument allows to define if the intention should be removed as well from the desire base. If the agent knows at least one gold mine that is not empty, it defines as its new target the closest gold mine."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'species miner skills: [moving] control: simple_bdi {\n    ...\n    plan choose_closest_gold_mine intention: choose_gold_mine instantaneous: true {\n\tlist<point> possible_mines <- get_beliefs_with_name(mine_at_location) collect (point(get_predicate(mental_state (each)).values["location_value"]));\n\tlist<point> empty_mines <- get_beliefs_with_name(empty_mine_location) collect (point(get_predicate(mental_state (each)).values["location_value"]));\n\tpossible_mines <- possible_mines - empty_mines;\n\tif (empty(possible_mines)) {\n\t    do remove_intention(extract_gold, true); \n\t} else {\n\t    target <- (possible_mines with_min_of (each distance_to self)).location;\n\t}\n\tdo remove_intention(choose_gold_mine, true); \n    }\n    ...\n}\n'})}),"\n",(0,i.jsxs)(t.p,{children:["The last plan called ",(0,i.jsx)(t.code,{children:"return_to_base"})," is defined to achieve the ",(0,i.jsx)(t.code,{children:"sell_gold"})," intention. The agent moves in the direction of the market using the ",(0,i.jsx)(t.code,{children:"goto"})," action. When the agent reaches the market, it sells its gold nugget to it: first, it removes the belief that it has a gold nugget, then it removes the intention and the desire to sell golds, at last, it increments its ",(0,i.jsx)(t.code,{children:"gold_sold"})," variable."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"species miner skills: [moving] control: simple_bdi {\n    ...\n    plan return_to_base intention: sell_gold {\n\tdo goto target: the_market ;\n\tif (the_market.location = location)  {\n\t    do remove_belief(has_gold);\n\t    do remove_intention(sell_gold, true);\n\t    gold_sold <- gold_sold + 1;\n\t}\n    }\n    ...\n}\n"})}),"\n",(0,i.jsx)(t.h2,{id:"gobal-section",children:"Gobal section"}),"\n",(0,i.jsx)(t.p,{children:"We define two new global variables:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"nb_miners"}),": number of gold miners."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"inequality"}),": recomputed at each simulation step: standard deviation of the number of gold nuggets extracted per miners."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["In the global ",(0,i.jsx)(t.code,{children:"init"}),", after creating the gold mines and the market, we create the gold miner agents."]}),"\n",(0,i.jsxs)(t.p,{children:["At last, we define a global reflex ",(0,i.jsx)(t.code,{children:"end_simulation"})," that is activated when all the gold mines are empty and no more miner has a gold nugget and that pauses the simulation and display the gold sold by each miner."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'global {\n    ...\n    int nb_minerd <- 5;\n    float inequality <- 0.0 update:standard_deviation(miner collect each.gold_sold);\n    ...\n    init {\n\t...\n\tcreate miner number: nb_miner;\n    }\n\t\n    reflex end_simulation when: sum(gold_mine collect each.quantity) = 0 and empty(miner where each.has_belief(has_gold)){\n\tdo pause;\n        ask miner {\n\t\twrite name + " : " +gold_sold;\n\t}\n    }\n}\n'})}),"\n",(0,i.jsx)(t.h2,{id:"map-display",children:"Map display"}),"\n",(0,i.jsx)(t.p,{children:"We add to the map display the miner species.\nWe also create a chart showing the gold sold of each miner."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:'experiment GoldBdi type: gui {\n    output {\n\tdisplay map type: opengl {\n\t    species market ;\n\t    species gold_mine ;\n\t    species miner;\n\t}\n\n        display chart {\n\t    chart "Money" type: series {\n\t\tdatalist legend: miner accumulate each.name value: miner accumulate each.gold_sold color: miner accumulate each.my_color;\n\t\t}\n\t}\n\n    }\n}\n'})}),"\n",(0,i.jsx)(t.h2,{id:"complete-model",children:"Complete Model"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-gaml",metastring:"reference",children:"https://github.com/gama-platform/gama/blob/GAMA_1.9.2/msi.gaml.architecture.simplebdi/models/BDI%20Architecture/models/Tutorial/BDI%20tutorial%202.gaml\n"})})]})}function c(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>l});var i=n(96540);const o={},s=i.createContext(o);function a(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);