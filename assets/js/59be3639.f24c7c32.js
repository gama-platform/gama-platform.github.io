"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[54776],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>m});var r=t(67294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function a(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function c(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},i=Object.keys(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=r.createContext({}),l=function(e){var n=r.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):a(a({},n),e)),t},p=function(e){var n=l(e.components);return r.createElement(s.Provider,{value:n},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},f=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,p=c(e,["components","mdxType","originalType","parentName"]),d=l(t),f=o,m=d["".concat(s,".").concat(f)]||d[f]||u[f]||i;return t?r.createElement(m,a(a({ref:n},p),{},{components:t})):r.createElement(m,a({ref:n},p))}));function m(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var i=t.length,a=new Array(i);a[0]=f;var c={};for(var s in n)hasOwnProperty.call(n,s)&&(c[s]=n[s]);c.originalType=e,c[d]="string"==typeof e?e:o,a[1]=c;for(var l=2;l<i;l++)a[l]=t[l];return r.createElement.apply(null,a)}return r.createElement.apply(null,t)}f.displayName="MDXCreateElement"},80825:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>s,default:()=>m,frontMatter:()=>c,metadata:()=>l,toc:()=>d});var r=t(87462),o=t(63366),i=(t(67294),t(3905)),a=["components"],c={"^title":"ContinuousFieldofVision"},s=void 0,l={unversionedId:"ContinuousFieldofVision.gaml",id:"ContinuousFieldofVision.gaml",title:"ContinuousFieldofVision.gaml",description:"Path: Library models/Modeling/Spatial Topology/Agent movement/Continuous Field of Vision.gaml",source:"@site/../docs/ContinuousFieldofVision.gaml.md",sourceDirName:".",slug:"/ContinuousFieldofVision.gaml",permalink:"/wiki/next/ContinuousFieldofVision.gaml",draft:!1,editUrl:"https://github.com/gama-platform/gama/wiki/ContinuousFieldofVision.gaml/_edit",tags:[],version:"current",frontMatter:{"^title":"ContinuousFieldofVision"}},p={},d=[],u={toc:d},f="wrapper";function m(e){var n=e.components,t=(0,o.Z)(e,a);return(0,i.kt)(f,(0,r.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("img",{width:"960",alt:"Annotation 2023-04-15 141132_continuousFieldOfVision",src:"https://user-images.githubusercontent.com/4437331/232223027-6ef84a3e-3e37-4dfe-84cb-82939ca44235.png"}),(0,i.kt)("p",null,"Path: Library models/Modeling/Spatial Topology/Agent movement/Continuous Field of Vision.gaml"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-java"},"\n/**\n* Name: fieldofvision\n* Author: Patrick Taillandier\n* Description: This model illustrate how to use the masked_by operator to compute the field of vision of an agent (with obtsacles)\n* Tags: perception, spatial_computation, masked_by\n*/\n\nmodel fieldofvision\n\nglobal {\n    //number of obstacles\n    int nb_obstacles <- 20 parameter: true;\n    \n    //perception distance\n    float perception_distance <- 40.0 parameter: true;\n    \n    //precision used for the masked_by operator (default value: 120): the higher the most accurate the perception will be, but it will require more computation\n    int precision <- 600 parameter: true;\n    \n    //space where the agent can move.\n    geometry free_space <- copy(shape);\n    init {\n        create obstacle number:nb_obstacles {\n            shape <- rectangle(2+rnd(20), 2+rnd(20));\n            free_space <- free_space - shape;\n        }\n        \n        create people  {\n            location <- any_location_in(free_space);\n        }\n    }\n}\n\nspecies obstacle {\n    aspect default {\n        draw shape color: #gray border: #black;\n    }\n}\nspecies people skills: [moving]{\n    //zone of perception\n    geometry perceived_area;\n    \n    //the target it wants to reach\n    point target ;\n    \n    reflex move {\n        if (target = nil ) {\n            if (perceived_area = nil) or (perceived_area.area < 2.0) {\n                //if the agent has no target and if the perceived area is empty (or too small), it moves randomly inside the free_space\n                do wander bounds: free_space;\n            } else {\n                //otherwise, it computes a new target inside the perceived_area .\n                target <- any_location_in(perceived_area);\n            }\n        } else {\n            //if it has a target, it moves towards this target\n            do goto target: target;\n            \n            //if it reaches its target, it sets it to nil (to choose a new target)\n            if (location = target)  {\n                target <- nil;\n            }\n        }\n    }\n    //computation of the perceived area\n    reflex update_perception {\n        //the agent perceived a cone (with an amplitude of 60\xb0) at a distance of  perception_distance (the intersection with the world shape is just to limit the perception to the world)\n        perceived_area <- (cone(heading-30,heading+30) intersection world.shape) intersection circle(perception_distance); \n        \n        //if the perceived area is not nil, we use the masked_by operator to compute the visible area from the perceived area according to the obstacles\n        if (perceived_area != nil) {\n            perceived_area <- perceived_area masked_by (obstacle,precision);\n\n        }\n    }\n    \n    aspect body {\n        draw triangle(2) rotate:90 + heading color: #red;\n    }\n    aspect perception {\n        if (perceived_area != nil) {\n            draw perceived_area color: #green;\n            draw circle(1) at: target color: #magenta;\n        }\n    }\n}\n\nexperiment fieldofvision type: gui {\n    float minimum_cycle_duration <- 0.05;\n    output synchronized: true {\n        display view{\n            species obstacle;\n            species people aspect: perception transparency: 0.5;\n            species people aspect: body;\n        }\n    }\n}\n\n")))}m.isMDXComponent=!0}}]);